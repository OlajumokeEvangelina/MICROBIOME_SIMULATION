---
title: "Microbiome Simulation Analysis"
output: pdf_document
author: "Olajumoke Evangelina Owokotomo"
date: "6/13/2019"
header-includes:
- \newcommand{\bcenter}{\begin{center}}
- \newcommand{\ecenter}{\end{center}}
---


```{r setup, include=FALSE}

library("Biobase")
library("grid")
library("ggplot2")
library("nlme")
library(stringr)
library(dplyr)
library(phyloseq)
library(tidyr)
library(ggpubr)
library(gridExtra)
library(IntegratedJM)
library(mvtnorm)
library(xtable)

# For the BVS part

library(rjags) 
library(R2jags)
library(runjags)
library(purrr)
library(parallel)

load("Results.RData")

knitr::opts_chunk$set(echo = TRUE)
```



## General information 

* This is a simulation study to study the relatonship between the probability of inclusion from the  BVS approach, the $R^2_h$  from the information theory approach and the adjusted association from the joint moelling approach.

## Simulation procedure (One dataset analysis)
For simulating the dataset the following steps and values were used;

* The joint error term for $X$ and $Y$  was assumed to have mean = (0,0) and covariance matrix = $\varepsilon$
$\begin{bmatrix}
\sigma^2_x & \sigma^2_{xy}  \\
\sigma^2_{xy} & \sigma^2_y \\
\end{bmatrix}$

* The $\sigma^2_x = \sigma^2_y = 1$.

* $\rho_{xy} = \sigma^2_{xy}$ because $\sigma^2_x = \sigma^2_y = 1$.

* $\rho_{xy} = c(0.25, 0.50, 0.75, 0.90)$.

* $\varepsilon_1 = \begin{bmatrix}
1 & 0.25  \\
0.25 & 1 \\
\end{bmatrix}$,  $\varepsilon_2 = \begin{bmatrix}
1 & 0.5  \\
0.5 & 1 \\
\end{bmatrix}$,   $\varepsilon_3 = \begin{bmatrix}
1 & 0.75  \\
0.75 & 1 \\
\end{bmatrix}$,   $\varepsilon_4 = \begin{bmatrix}
1 & 0.90  \\
0.90 & 1 \\
\end{bmatrix}$.

* The number of subjects in each treatment group is 50, therfore $Z_i = 100$.

* $$X_i = \alpha_0 + \alpha_1 Z_i + \epsilon_i^x$$
   $$Y_i = \beta_0 + \beta_1 Z_i + \epsilon_i^y$$.
   
* $\epsilon_i^x$ and $\epsilon_i^y$  were obtained  using rmvnorm(100, c(0,0), $\varepsilon$) for each correlation.

* Using the following true value:  $\alpha_0 =1, \ \ \ \alpha_1 = 5, \ \ \ \beta_0 = 5, \ \ \ \beta_1 = 2$.

* The combination of the true parameter values and $\epsilon_i^x$ and $\epsilon_i^y$ was then used to simulate
1000 dataset for each correllation; we therefore have 1000 dataset for each cor=0.25, for cor=0.5, for cor=0.75 and for cor=0.90.

* Models for the Joint model approach
$$ X_i = \mu_i^x  + \alpha Z_i + \epsilon_i^x$$
$$ Y_i = \mu_i^y  + \beta Z_i + \epsilon_i^y$$
$$R^2 = corr(\epsilon_i^x,\epsilon_i^y)$$

* Models for the Information theory approach
$$ Y_i^1 = \mu_i^{y_1}  + \alpha Z_i + \epsilon_i^{y_1} ------- \text{Model1}$$
$$ Y_i^2 = \mu_i^{y_2}  + \beta Z_i + \gamma X_i +\epsilon_i^{y_2} ------- \text{Model2}$$
$$ G^2 = -2(\text{log1} - \text{log2})$$
$$ R^2_h = 1- e^\frac{-G^2}{n} $$ 

* Models for the BVS approach
$$ X_i = \mu_i^{x}  + \theta_1 \phi_1 Z_i + \epsilon_i^{x} \ \ \ \ \ \ \ \ \ \text{where} \ \ \ \ \alpha = \theta_1 \phi_1$$
$$ Y_i = \mu_i^{y}  + \theta_2 \phi_2 Z_i + \theta_3 \phi_3 X_i +\epsilon_i^{y}  \ \ \ \ \ \ \ \ \ \text{where} \ \ \ \ \beta = \theta_2 \phi_2 \ \ \ \ \text{and} \ \ \ \ \gamma = \theta_3 \phi_3 $$
$$R^2_{BVS} = P(\phi_3 =1) $$


```{r first, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
###############################################################
# Simulation                                                  #
# n: sample size at each group                                #
# Z: treatment (0/1)                                          #
# mu & Sigma: mean and covariance matrix for the error        #
###############################################################

##############  SIMULATING DATA #####################
corr <- c(0.9,0.75,0.5,0.25)

mu<-c(0,0)
varx=1
vary=1

Sigma = list()
for (j in 1:4) {
  Sigma[[j]]<-matrix(c(varx,corr[j],corr[j],vary),2,2)
}


alpha0<-1
alpha1<-5
beta0<-5
beta1<-2

n<-50
zi<-as.numeric(c(rep(0,n),rep(1,n)))
B<-1000
r.square.h<-c(1:B)


x = array(data = NA, dim=c(100,1000,4)) ; y = array(data = NA, dim=c(100,1000,4))

eps = list(); se=list(); ce=list()

set.seed(1234)
for(i in 1:B){
  for (k in 1:4) {
eps[[k]] <- rmvnorm(n,mu,Sigma[[k]])
x[,i,k]<-alpha0+alpha1*zi+eps[[k]][,1]
y[,i,k]<-beta0+beta1*zi+eps[[k]][,2]

corr <- c(0.9,0.75,0.5,0.25)

se[[k]] <- data.frame(x[,,k][,])
ce[[k]] <- data.frame(y[,,k][,])
  }
}


###########################  information theory ###########################
log1<-c(1:B)
log2<-c(1:B)
anov<-list()
G2<-c(1:B)
R2h<-c(1:B)

R2h <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
intercept1 <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
intercept2 <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
teffect1 <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
teffect2 <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
effectofx <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
pvalue <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))

list1 <- list()

## fitting linear model (the clinical endpoint and the classifying variable)
set.seed(1234)
for(i in 1:B)
{
  for(q in 1:4){
  fit.1<-lm(ce[[q]][,i]~zi)
  log1[i] <- as.numeric(logLik(fit.1))
  int1 <- summary(fit.1)$coefficients[1,1]
  trteffect1 <- summary(fit.1)$coefficients[2,1]

## fitting linear model (the clinical endpoint and the classifying variable and the biomarker)
  fit.2 <-lm(ce[[q]][,i]~zi+se[[q]][,i])
  log2[i] <- as.numeric(logLik(fit.2))
  int2 <- summary(fit.2)$coefficients[1,1]
  trteffect2 <- summary(fit.2)$coefficients[2,1]
  xeffect <- summary(fit.2)$coefficients[3,1]
  
  LRT <- anova(fit.1,fit.2)

   G2[i] <- -2*(log1[i] - log2[i])
   R2h[i,q] <- 1- exp(-G2[i]/length(zi))
   intercept1[i,q] <- int1
   intercept2[i,q] <- int2
   teffect1[i,q] <- trteffect1
   teffect2[i,q] <- trteffect2
   effectofx[i,q] <- xeffect
   pvalue[i,q] <- as.numeric(LRT$`Pr(>F)`[2])   
  }
}


  list1[[1]] <- R2h
  list1[[2]] <- intercept1
  list1[[3]] <- intercept2
  list1[[4]] <- teffect1
  list1[[5]] <- teffect2
  list1[[6]] <- effectofx
  list1[[7]] <- pvalue

  names(list1) = c("R2h", "intercept1", "intercept2","teffect1", "teffect2", "effectofx", "pvalue")
  colnames(list1$R2h) = c("0.9", "0.75", "0.5", "0.25")
  colnames(list1$intercept1) = c("0.9", "0.75", "0.5", "0.25")
  colnames(list1$intercept2) = c("0.9", "0.75", "0.5", "0.25")
  colnames(list1$teffect1) = c("0.9", "0.75", "0.5", "0.25")
  colnames(list1$teffect2) = c("0.9", "0.75", "0.5", "0.25")
  colnames(list1$effectofx) = c("0.9", "0.75", "0.5", "0.25")
  colnames(list1$pvalue) = c("0.9", "0.75", "0.5", "0.25")
  
  
  

################   The Rsquared adjusted   ####################
AdjustedR2 <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
varend <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
varsurr <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
varcov <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
intercept1 <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
intercept2 <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
teffect1 <- as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))
teffect2 <-  as.data.frame(matrix(data = NA, nrow = 1000, ncol=4))

  list2 <- list()

for(i in 1:B) {
  for(q in 1:4) {
    dat <- data.frame(Resp=c(ce[[q]][,i],se[[q]][,i])
                      , ind = rep(c(1,2),each=100), z = c(zi,zi),
                      Subject = rep(1:100, times = 2))
    
    m1 <- gls(Resp ~ factor(ind)*z, data = dat,
              correlation = corSymm(form = ~ ind | Subject),
              weights = varIdent(form = ~ 1 | ind), method = "ML")
    
    mvcov <- getVarCov(m1)
    AdjustedR2[i,q] <- mvcov[1,2] / sqrt(mvcov[1,1] * mvcov[2,2])
    intercept1[i,q] <- unname(coef(m1)[1])
    intercept2[i,q] <- unname(coef(m1)[1]) + unname(coef(m1)[2])
    teffect1[i,q] <- unname(coef(m1)[3])
    teffect2[i,q] <- unname(coef(m1)[3]) + unname(coef(m1)[4])
    varend[i,q] <- mvcov[1,1]
    varsurr[i,q] <- mvcov[2,2]
    varcov[i,q] <- mvcov[1,2]
  }
}

list2[[1]] <- AdjustedR2
list2[[2]] <- intercept1
list2[[3]] <- intercept2
list2[[4]] <- teffect1
list2[[5]] <- teffect2 
list2[[6]] <- varend
list2[[7]] <- varsurr
list2[[8]] <- varcov


names(list2) = c("R2Adj", "intercept1", "intercept2","teffect1", "teffect2", "varend", "varsurr", "varcov")
  colnames(list2$R2Adj) = c("0.9", "0.75", "0.5", "0.25")  
  colnames(list2$intercept1) = c("0.9", "0.75", "0.5", "0.25")
  colnames(list2$intercept2) = c("0.9", "0.75", "0.5", "0.25")  
  colnames(list2$teffect1) = c("0.9", "0.75", "0.5", "0.25")  
  colnames(list2$teffect2) = c("0.9", "0.75", "0.5", "0.25")  
  colnames(list2$varend) = c("0.9", "0.75", "0.5", "0.25")  
  colnames(list2$varsurr) = c("0.9", "0.75", "0.5", "0.25")  
  colnames(list2$varcov) = c("0.9", "0.75", "0.5", "0.25") 
  
```


```{r bvs, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
names(Final_results) <- c(0.9,0.75,0.5,0.25)
  
  correlatn <- data.frame(ind = c(Final_results$`0.9`$Ind, Final_results$`0.75`$Ind, Final_results$`0.5`$Ind,Final_results$`0.25`$Ind),
                        R2adj = c(list2$R2Adj$`0.9`,list2$R2Adj$`0.75`,list2$R2Adj$`0.5`,list2$R2Adj$`0.25`),
                        R2h = c(list1$R2h$`0.9`,list1$R2h$`0.75`,list1$R2h$`0.5`,list1$R2h$`0.25`),
                        Corr = as.factor(rep(c(0.9,0.75,0.5,0.25),each=1000)))

no0.25 <- correlatn[1:3000,]


```


## ADJUSTED ASSOCIATION AND INFOMATION APPROACH
```{r g1, echo=FALSE, warning=FALSE, warning=FALSE,  fig.align = "center"}
ggplot(no0.25, aes(x=R2adj, y=R2h, color=Corr)) + geom_point() + xlab("Adjusted association") + ylab("Rsquare h")
```

##  PROBABILITY OF INCLUSION AND ADJUSTED ASSOCIATION
```{r g2, echo=FALSE, warning=FALSE, warning=FALSE,  fig.align = "center"}
ggplot(no0.25, aes(x=ind, y=R2adj, color=Corr)) + geom_point() + xlab("Prob of inclusion") + ylab("Adjusted association")
```

## PROBABILITY OF INCLUSION AND INFOMATION APPROACH
```{r g3, echo=FALSE, warning=FALSE, warning=FALSE,  fig.align = "center"}
ggplot(no0.25, aes(x=ind, y=R2h, color=Corr)) + geom_point() + xlab("Prob of inclusion") + ylab("Rsquare h")
```

```{r tt, warning=FALSE, message=FALSE, cache=TRUE, echo=FALSE}
newcorr <- c(0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1)

trteffects <- NULL
surrogateeffect <- NULL
variancee <- NULL

for (i in 1:20) {
  trteffects[i] <- 2 - (newcorr[i] *5)
  surrogateeffect[i] <- newcorr[i]
  variancee[i] <- 1 - (newcorr[i] * newcorr[i])
}

dd <- data.frame(newcorr, trteffects, surrogateeffect, variancee)

```
